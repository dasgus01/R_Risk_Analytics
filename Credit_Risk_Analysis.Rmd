---
title: "Credit Risk Analysis"
author: "Sherry Liang"
date: "8/26/2018"
output: pdf_document
---

TASK
* Build classed logistic model to predict default
* Data has 54 features: 53 dependent variable and 1 target variable
* Use WoeBinning package to help on binning
* Use logistic regression with WoE of dependent variables
* Check for multicollinearity
* Use AUROC to determine the best model
* Provide validation results on the holdout sample
* Provide the final model scorecard
* Generate the top 4 adverse action for the scoring application

```{r setup, message = FALSE}

library(woeBinning)
library(scorecard)
library(ggplot2)
library(caret)
library(glmnet)
library(magrittr)
library(usdm)
library(pROC)
library(ROCR)

options(warn=-1)

```

```{r}

## first col is member_id, let's remove it 
train <- read.csv("train_record-1.csv")[,-1] # 9062   53 
test <- read.csv("test_record-1.csv")[,-1] # 3884   53

## take a look at the data 
# str(train)
# str(test)
## check NA in train 
# sapply(train,function(x) sum(is.na(x)))

mean(train$target)
mean(test$target)
```
The default rate of train and test are 13.87% and 13.69%

```{r}
train_info_value <- iv(train, "target")
head(train_info_value,10)

# filter variable via missing rate, iv, identical value rate
train_sel0 <- var_filter(train, "target",iv_limit = 0.1, missing_limit = 0.8)
# dim(train_sel)  # 9062  16
```

## Check VIF
```{r}
# check VIF ------
var_vif <- vif(train_sel0)
var_vif[order(-var_vif$VIF),]
# remove variables with VIF  higher than 8
var_selected <- as.character(subset(var_vif, VIF<8)$Variables)
train_sel <- train_sel0[, ..var_selected]
```


var_selected
[1] annual_inc           dti                  tot_coll_amt         total_rev_hi_lim    
 [5] bc_util              mo_sin_old_il_acct   mths_since_recent_bc percent_bc_gt_75    
 [9] tot_hi_cred_lim      target     
 
 
9 predictors are selected

```{r}

# woe binning ------
binning <-  woebin(train_sel, "target")
binning[[1]]
woebin_plot(binning$annual_inc)

# apply bins to train dataset
train_woe <- woebin_ply(train_sel, binning)  # dataframe

# glm ------
m1 <- glm( target ~ ., family = binomial(), data = train_woe)
summary(m1)  # AIC: 6989.7

# Select model by AIC
m_step <- step(m1,  trace=FALSE)
summary(m_step)
m <- eval(m_step$call)


# predicted proability
train_pred <- predict(m, type='response', train_woe)
perf_eva(train_woe$target, train_pred, type = c("ks","lift","roc","pr"))
```

Model AUC of train data set is 0.6417

## Validation

```{r}
# validation
test_sel <- test[, var_selected]
test_woe <- woebin_ply(test_sel, binning)

test_pred <- predict(m, type = 'response', test_woe)
perf_eva(test_woe$target, test_pred, type = c("ks","lift","roc","pr"))

```

AUC on test dataset is only 0.5888. There is slight overfitting in the model


Use default target points = 600, Odds = p/(1-p) = 0.137/(1-0.137) = 0.16, Points to Double the Odds = 20
```{r}
# scorecard
card <- scorecard(binning, m, points0 = 600, odds0 = 0.16, pdo = 20)
card[[1]] 
```

The basepoint is 600.

```{r, results = 'hide'}
# check the final score of the train and test data sets
score_train <- scorecard_ply( train, card )
score_test <- scorecard_ply( test, card )
```

```{r}
c(head(score_train,5),head(score_test,5))
```
```{r}
for (i in 2:10){
        print(card[[i]][,c(1:3,8,10,13)])
}
```

The score for all levels of each selected variable are shown as above. For example, the annual income in the range of [-Inf,45000),[45000,60000),[60000,95000),[95000, Inf) has the following scores: -7, -3, 5, 13.

The top 4 adverse actions for the scoring application are:

  + dti [23.5, Inf)                   -8
  + bc_util [95, Inf)                 -8
  + annual_inc  [-Inf,45000)          -7
  + mths_since_recent_bc [-Inf,16)    -6
  + total_rev_hi_lim  [-Inf,10000)    -6
